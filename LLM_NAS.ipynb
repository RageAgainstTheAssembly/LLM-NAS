{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d84520e-6999-4b98-8305-f08b54e2dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maleksanderk\u001b[0m (\u001b[33mnull-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "from llama_cpp import Llama\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "wandb.login()\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc23e51-f38e-41ae-af92-019fab824ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-PCIE-40GB\n",
      "GPU 1: NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # List all available GPUs\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No CUDA GPUs are available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f98dc1-3b65-4c2a-9c74-470fdd191e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 60000\n",
      "Testing dataset size: 10000\n",
      "Example Batch Shape - Images torch.Size([64, 1, 28, 28]) Labels: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Define data transformations (normalize the pixel values to the range [0, 1])\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training dataset\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the testing dataset\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Checking the length of the datasets and an example batch\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Testing dataset size:\", len(test_dataset))\n",
    "\n",
    "# Example batch from the training loader\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(\"Example Batch Shape - Images\", images.shape, \"Labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c59c2f-1e5f-4739-a78d-adb35e0ac26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility classe to track API usage when there is none\n",
    "class DummyUsage:\n",
    "    def __init__(prompt_tokens, completion_tokens):\n",
    "        self.prompt_tokens = prompt_tokens\n",
    "        self.completion_tokens = completion_tokens\n",
    "        \n",
    "# class to use OpenAI API\n",
    "class OpenAIModel:\n",
    "    def __init__(self, model_type):\n",
    "        self.client = OpenAI(\n",
    "            api_key='env.API_KEY',\n",
    "            base_url=\"https://api.proxyapi.ru/openai/v1\",\n",
    "        )\n",
    "        self.model_type = model_type\n",
    "    def completion(self, prompt):\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            model=self.model_type, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content, chat_completion.usage\n",
    "\n",
    "# class to run local models with LLama.cpp\n",
    "class LocalModel:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.model = Llama(model_path=self.model_path, n_gpu_layers=-1)\n",
    "    def completion(self, prompt):\n",
    "        return self.model(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c69dae-216f-473a-934c-01bab06f67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the backend model\n",
    "LLM_backend = OpenAIModel('gpt-4-turbo')\n",
    "\n",
    "# example module we can add to the model's arsenal\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection (if needed)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main path\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def convert_values(data):\n",
    "    converted_data = {}\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        if type(value) == int or type(value) == float or type(value) == bool:\n",
    "          converted_data[key] = value\n",
    "        else:\n",
    "          try:\n",
    "              # Try converting the value to a numeric type\n",
    "              converted_value = eval(value) if not value.startswith(\"(\") and value.lower() != 'true' and value.lower() != 'false' else tuple(map(int, value.strip('()').split(',')))\n",
    "          except:\n",
    "              # If it's not a numeric type, check for boolean values\n",
    "              if value.lower() == 'true':\n",
    "                  converted_value = True\n",
    "              elif value.lower() == 'false':\n",
    "                  converted_value = False\n",
    "              else:\n",
    "                  # If conversion fails, keep the original string value\n",
    "                  converted_value = value\n",
    "          \n",
    "          converted_data[key] = converted_value\n",
    "    \n",
    "    return converted_data\n",
    "\n",
    "# builds sequential model from JSON-like config\n",
    "def build_model(config):\n",
    "    layer_list = []\n",
    "    for key in config:\n",
    "        layer_config = config[key]\n",
    "        layer_type = layer_config.pop('type')\n",
    "        if layer_type == 'resblock':\n",
    "            # do smth\n",
    "            unpacked_layer_config = convert_values(layer_config)\n",
    "            layer_list.append(ResidualBlock(**unpacked_layer_config))\n",
    "        else:\n",
    "            unpacked_layer_config = convert_values(layer_config)\n",
    "            layer_list.append(getattr(torch.nn, layer_type)(**unpacked_layer_config))\n",
    "\n",
    "    return nn.Sequential(*layer_list)\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, num_epochs, gpu_ids=None):\n",
    "    # Setup Accelerator with specific GPUs\n",
    "    accelerator = Accelerator(device_placement=True, split_batches=False, cpu=False)\n",
    "    if gpu_ids is not None:\n",
    "        # Set specific GPUs to use\n",
    "        accelerator.state.device_ids = gpu_ids\n",
    "\n",
    "    # Prepare the model, optimizer, and data loaders\n",
    "    model, optimizer, train_loader, test_loader = accelerator.prepare(model, optim.Adam(model.parameters()), train_loader, test_loader)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    summary = ''\n",
    "    train_accuracy = 0\n",
    "    test_accuracy = 0\n",
    "    train_history = []\n",
    "    test_history = []\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = test_correct / test_total\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_history.append(train_accuracy)\n",
    "        test_history.append(test_accuracy)\n",
    "        epoch_result = f'Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {test_accuracy:.4f}'\n",
    "        #print(epoch_result)\n",
    "        summary += epoch_result + '\\n'\n",
    "\n",
    "    return summary, max(train_history), max(test_history)\n",
    "\n",
    "# initial conditions to initialize the model\n",
    "data_description = \"50K 28x28 grayscale images, each with a label from 10 classes\"\n",
    "task_description = \"Image Classification into 10 classes\"\n",
    "# seed model, not strictly necessary\n",
    "gpt4_model_string = '''\n",
    "{\n",
    "  \"layer_0\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"1\",\n",
    "    \"out_channels\": \"32\",\n",
    "    \"kernel_size\": \"3\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"1\"\n",
    "  },\n",
    "  \"layer_1\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_2\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_3\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"32\",\n",
    "    \"out_channels\": \"64\",\n",
    "    \"kernel_size\": \"3\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"1\"\n",
    "  },\n",
    "  \"layer_4\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_5\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_6\": {\n",
    "    \"type\": \"Flatten\",\n",
    "    \"start_dim\": \"1\",\n",
    "    \"end_dim\": \"-1\"\n",
    "  },\n",
    "  \"layer_7\": {\n",
    "    \"type\": \"Linear\",\n",
    "    \"in_features\": \"64 * 7 * 7\",\n",
    "    \"out_features\": \"128\",\n",
    "    \"bias\": \"true\"\n",
    "  },\n",
    "  \"layer_8\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_9\": {\n",
    "    \"type\": \"Linear\",\n",
    "    \"in_features\": \"128\",\n",
    "    \"out_features\": \"10\",\n",
    "    \"bias\": \"true\"\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "llama8b_model_string = '''\n",
    "{\n",
    "  \"layer_0\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"1\",\n",
    "    \"out_channels\": \"64\",\n",
    "    \"kernel_size\": \"3\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"1\"\n",
    "  },\n",
    "  \"layer_1\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_2\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_3\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"64\",\n",
    "    \"out_channels\": \"128\",\n",
    "    \"kernel_size\": \"3\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"1\"\n",
    "  },\n",
    "  \"layer_4\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_5\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_6\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"128\",\n",
    "    \"out_channels\": \"256\",\n",
    "    \"kernel_size\": \"3\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"1\"\n",
    "  },\n",
    "  \"layer_7\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_8\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_9\": {\n",
    "    \"type\": \"Flatten\",\n",
    "    \"start_dim\": \"1\",\n",
    "    \"end_dim\": \"-1\"\n",
    "  },\n",
    "  \"layer_10\": {\n",
    "    \"type\": \"Linear\",\n",
    "    \"in_features\": \"256 * 7 * 7\",\n",
    "    \"out_features\": \"128\",\n",
    "    \"bias\": \"true\"\n",
    "  },\n",
    "  \"layer_11\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_12\": {\n",
    "    \"type\": \"Linear\",\n",
    "    \"in_features\": \"128\",\n",
    "    \"out_features\": \"10\",\n",
    "    \"bias\": \"true\"\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "llama70b_model_string = '''\n",
    "{\n",
    "  \"layer_0\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"1\",\n",
    "    \"out_channels\": \"16\",\n",
    "    \"kernel_size\": \"5\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"2\"\n",
    "  },\n",
    "  \"layer_1\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_2\": {\n",
    "    \"type\": \"BatchNorm2d\",\n",
    "    \"num_features\": \"16\"\n",
    "  },\n",
    "  \"layer_3\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_4\": {\n",
    "    \"type\": \"Conv2d\",\n",
    "    \"in_channels\": \"16\",\n",
    "    \"out_channels\": \"32\",\n",
    "    \"kernel_size\": \"3\",\n",
    "    \"stride\": \"1\",\n",
    "    \"padding\": \"1\"\n",
    "  },\n",
    "  \"layer_5\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_6\": {\n",
    "    \"type\": \"BatchNorm2d\",\n",
    "    \"num_features\": \"32\"\n",
    "  },\n",
    "  \"layer_7\": {\n",
    "    \"type\": \"MaxPool2d\",\n",
    "    \"kernel_size\": \"2\",\n",
    "    \"stride\": \"2\",\n",
    "    \"padding\": \"0\",\n",
    "    \"dilation\": \"1\",\n",
    "    \"ceil_mode\": \"false\"\n",
    "  },\n",
    "  \"layer_8\": {\n",
    "    \"type\": \"Flatten\",\n",
    "    \"start_dim\": \"1\",\n",
    "    \"end_dim\": \"-1\"\n",
    "  },\n",
    "  \"layer_9\": {\n",
    "    \"type\": \"Linear\",\n",
    "    \"in_features\": \"32 * 7 * 7\",\n",
    "    \"out_features\": \"128\",\n",
    "    \"bias\": \"true\"\n",
    "  },\n",
    "  \"layer_10\": {\n",
    "    \"type\": \"ReLU\"\n",
    "  },\n",
    "  \"layer_11\": {\n",
    "    \"type\": \"Linear\",\n",
    "    \"in_features\": \"128\",\n",
    "    \"out_features\": \"10\",\n",
    "    \"bias\": \"true\"\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "# format to follow when running self-reflection\n",
    "reflection_format = '''\n",
    "{\n",
    "    \"differences_between_models\": [],\n",
    "    \"new_model_performance_better\": bool,\n",
    "    \"why_performance_improved\": \"\",\n",
    "    \"model_overfit\": bool,\n",
    "    \"how_to_improve_architecture_further\": [],\n",
    "    \"optimizer_choice\": \"\",\n",
    "    \"how_many_epochs_to_choose\": int,\n",
    "    \"learning_rate_choice\": float,\n",
    "    \"summary\": \"\"\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "def extract_between_tokens(input_string, start_token, end_token):\n",
    "    start_index = input_string.find(start_token) + len(start_token)\n",
    "    end_index = input_string.find(end_token, start_index)\n",
    "\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        result = input_string[start_index:end_index]\n",
    "        return result\n",
    "    else:\n",
    "        return input_string\n",
    "    \n",
    "def remove_comments(json_str):\n",
    "    # Remove single-line comments\n",
    "    json_str = re.sub(r'//.*', '', json_str)\n",
    "    \n",
    "    # Remove multi-line comments\n",
    "    json_str = re.sub(r'/\\*(.*?)\\*/', '', json_str, flags=re.DOTALL)\n",
    "\n",
    "    return json_str\n",
    "\n",
    "# main function to generate a new model\n",
    "def get_new_model(data_description, task_description, model_string, summary, reflection=None):\n",
    "    prompt = f'''\n",
    "    You are a deep learning engineer. You will be provided with a model in JSON format, its perfomance, a task and a data description.\n",
    "    You are only capable of replying with a valid JSON containing a new improved model (same format) that should perform better than the one you were given.\n",
    "    Warning: all values must be presented as strings\n",
    "    Warning: output must be valid JSON, you will be penalised for mistakes, such as adding comments or anything to violate that format\n",
    "    Warning: you will be penalised for overfitting\n",
    "    Use any Pytorch modules you want or use \"layer_...\": {{\n",
    "        \"type\": \"resblock\",\n",
    "        \"in_channels\": \"...\",\n",
    "        \"out_channels\": \"...\",\n",
    "        \"kernel_size\": \"...\",\n",
    "        \"stride\": \"...\",\n",
    "        \"padding\": \"...\"\n",
    "    }} to use a resnet block, substitute ... with the needed values.\n",
    "  \n",
    "    Data description:\n",
    "    {data_description}\n",
    "\n",
    "    Task description:\n",
    "    {task_description}\n",
    "\n",
    "    Old model in JSON format:\n",
    "    {model_string}\n",
    "\n",
    "    Old model perfomance:\n",
    "    {summary}\n",
    "    \n",
    "    '''\n",
    "    if reflection is not None:\n",
    "        prompt += f'''Consider the following information when making your decision: {reflection}'''\n",
    "    completion, usage = LLM_backend.completion(prompt)\n",
    "    proper_string = extract_between_tokens(completion.strip(), \"```json\", \"```\")\n",
    "    clean_proper_string = remove_comments(proper_string)\n",
    "    return clean_proper_string, usage\n",
    "\n",
    "# main function to perform error correction\n",
    "def fix_model(model_string, error):\n",
    "    prompt = f'''\n",
    "    You are a deep learning engineer. I will present you with a model represented in JSON form and an error it encountered during training.\n",
    "    Fix the error and reply only with the fixed model in the same JSON format.\n",
    "    All values must be formatted as strings and enclosed in double quotes.\n",
    "    Old model:\n",
    "    {model_string}\n",
    "    \n",
    "    Error:\n",
    "    {error}\n",
    "    '''\n",
    "    completion, usage = LLM_backend.completion(prompt)\n",
    "    proper_string = extract_between_tokens(completion.strip(), \"```json\", \"```\")\n",
    "    clean_proper_string = remove_comments(proper_string)\n",
    "    return clean_proper_string, usage\n",
    "\n",
    "# main function to perform self-reflection\n",
    "def reflect(data_description, task_description, old_model_string, new_model_string, old_summary, new_summary, reflection_format):\n",
    "    prompt = f'''\n",
    "    You are a deep learning engineer. You will be provided with two models in JSON format, their perfomances, a task and a data description.\n",
    "    You are only capable of replying with a valid JSON containing a brief reflection on the differences between the models and advice on further improvement.\n",
    "    Warning: you will be penalised for writing code, you must reply with plain text only.\n",
    "    Warning: you will be penalised for deviating from the format\n",
    "    What are the differences between the models?\n",
    "    Did the new one perform better?\n",
    "    Why?\n",
    "    Does the model overfit?\n",
    "    How should the model be changed to improve perfomance?\n",
    "    Summarise, be very concise.\n",
    "    Give specific concrete recommendations about changes to the model\n",
    "\n",
    "    Response format you must fill:\n",
    "    {reflection_format}\n",
    "    \n",
    "    Data description:\n",
    "    {data_description}\n",
    "\n",
    "    Task description:\n",
    "    {task_description}\n",
    "\n",
    "    Old model in JSON format:\n",
    "    {old_model_string}\n",
    "\n",
    "    Old model perfomance:\n",
    "    {old_summary}\n",
    "\n",
    "    Current model in JSON format:\n",
    "    {new_model_string}\n",
    "\n",
    "    Current model perfomance:\n",
    "    {new_summary}\n",
    "\n",
    "    Current settings:\n",
    "    \"optimizer\": \"Adam\"\n",
    "    \"num_epochs\": {num_epochs}\n",
    "    \n",
    "    '''\n",
    "    completion, usage = LLM_backend.completion(prompt)\n",
    "    return completion.strip(), usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8ef9d-f734-420a-a7e2-c5c1ec35b4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/vk/stud_lab_vk_03/local_experiment/wandb/run-20240419_200323-bncxu7lf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/null-team/LLM-NAS-Experiments/runs/bncxu7lf' target=\"_blank\">deft-cosmos-45</a></strong> to <a href='https://wandb.ai/null-team/LLM-NAS-Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/null-team/LLM-NAS-Experiments' target=\"_blank\">https://wandb.ai/null-team/LLM-NAS-Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/null-team/LLM-NAS-Experiments/runs/bncxu7lf' target=\"_blank\">https://wandb.ai/null-team/LLM-NAS-Experiments/runs/bncxu7lf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "\n",
      "{\n",
      "  \"layer_0\": {\n",
      "    \"type\": \"Conv2d\",\n",
      "    \"in_channels\": \"1\",\n",
      "    \"out_channels\": \"32\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_1\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_2\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\",\n",
      "    \"dilation\": \"1\",\n",
      "    \"ceil_mode\": \"false\"\n",
      "  },\n",
      "  \"layer_3\": {\n",
      "    \"type\": \"Conv2d\",\n",
      "    \"in_channels\": \"32\",\n",
      "    \"out_channels\": \"64\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_4\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_5\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\",\n",
      "    \"dilation\": \"1\",\n",
      "    \"ceil_mode\": \"false\"\n",
      "  },\n",
      "  \"layer_6\": {\n",
      "    \"type\": \"Flatten\",\n",
      "    \"start_dim\": \"1\",\n",
      "    \"end_dim\": \"-1\"\n",
      "  },\n",
      "  \"layer_7\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"64 * 7 * 7\",\n",
      "    \"out_features\": \"128\",\n",
      "    \"bias\": \"true\"\n",
      "  },\n",
      "  \"layer_8\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_9\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"128\",\n",
      "    \"out_features\": \"10\",\n",
      "    \"bias\": \"true\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  0.421642 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vk/stud_lab_vk_03/local_experiment/local_venv/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(split_batches=False)\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 25/25 [04:26<00:00, 10.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8455, Validation Accuracy: 0.8843\n",
      "Epoch 2/25, Train Accuracy: 0.9017, Validation Accuracy: 0.9035\n",
      "Epoch 3/25, Train Accuracy: 0.9185, Validation Accuracy: 0.9026\n",
      "Epoch 4/25, Train Accuracy: 0.9279, Validation Accuracy: 0.9192\n",
      "Epoch 5/25, Train Accuracy: 0.9373, Validation Accuracy: 0.9143\n",
      "Epoch 6/25, Train Accuracy: 0.9465, Validation Accuracy: 0.9236\n",
      "Epoch 7/25, Train Accuracy: 0.9539, Validation Accuracy: 0.9113\n",
      "Epoch 8/25, Train Accuracy: 0.9604, Validation Accuracy: 0.9206\n",
      "Epoch 9/25, Train Accuracy: 0.9660, Validation Accuracy: 0.9184\n",
      "Epoch 10/25, Train Accuracy: 0.9725, Validation Accuracy: 0.9260\n",
      "Epoch 11/25, Train Accuracy: 0.9769, Validation Accuracy: 0.9215\n",
      "Epoch 12/25, Train Accuracy: 0.9805, Validation Accuracy: 0.9213\n",
      "Epoch 13/25, Train Accuracy: 0.9834, Validation Accuracy: 0.9197\n",
      "Epoch 14/25, Train Accuracy: 0.9867, Validation Accuracy: 0.9191\n",
      "Epoch 15/25, Train Accuracy: 0.9873, Validation Accuracy: 0.9165\n",
      "Epoch 16/25, Train Accuracy: 0.9898, Validation Accuracy: 0.9202\n",
      "Epoch 17/25, Train Accuracy: 0.9896, Validation Accuracy: 0.9108\n",
      "Epoch 18/25, Train Accuracy: 0.9913, Validation Accuracy: 0.9168\n",
      "Epoch 19/25, Train Accuracy: 0.9929, Validation Accuracy: 0.9235\n",
      "Epoch 20/25, Train Accuracy: 0.9923, Validation Accuracy: 0.9203\n",
      "Epoch 21/25, Train Accuracy: 0.9925, Validation Accuracy: 0.9169\n",
      "Epoch 22/25, Train Accuracy: 0.9932, Validation Accuracy: 0.9204\n",
      "Epoch 23/25, Train Accuracy: 0.9939, Validation Accuracy: 0.9166\n",
      "Epoch 24/25, Train Accuracy: 0.9946, Validation Accuracy: 0.9163\n",
      "Epoch 25/25, Train Accuracy: 0.9944, Validation Accuracy: 0.9187\n",
      "\n",
      "Training time:  267.31244134902954\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vk/stud_lab_vk_03/local_experiment/local_venv/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration cost:  7.847999999999999\n",
      "Iteration:  1\n",
      "{\n",
      "  \"layer_0\": {\n",
      "    \"type\": \"Conv2d\",\n",
      "    \"in_channels\": \"1\",\n",
      "    \"out_channels\": \"32\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_1\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"32\"\n",
      "  },\n",
      "  \"layer_2\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_3\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\",\n",
      "    \"dilation\": \"1\",\n",
      "    \"ceil_mode\": \"false\"\n",
      "  },\n",
      "  \"layer_4\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"32\",\n",
      "    \"out_channels\": \"64\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_5\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"64\"\n",
      "  },\n",
      "  \"layer_6\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_7\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\",\n",
      "    \"dilation\": \"1\",\n",
      "    \"ceil_mode\": \"false\"\n",
      "  },\n",
      "  \"layer_8\": {\n",
      "    \"type\": \"Flatten\",\n",
      "    \"start_dim\": \"1\",\n",
      "    \"end_dim\": \"-1\"\n",
      "  },\n",
      "  \"layer_9\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"3136\",\n",
      "    \"out_features\": \"128\",\n",
      "    \"bias\": \"true\"\n",
      "  },\n",
      "  \"layer_10\": {\n",
      "    \"type\": \"BatchNorm1d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_11\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_12\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.5\"\n",
      "  },\n",
      "  \"layer_13\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"128\",\n",
      "    \"out_features\": \"10\",\n",
      "    \"bias\": \"true\"\n",
      "  }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  (9): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU()\n",
      "  (12): Dropout(p=0.5, inplace=False)\n",
      "  (13): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  0.477706 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [05:19<00:00, 12.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8728, Validation Accuracy: 0.9086\n",
      "Epoch 2/25, Train Accuracy: 0.9099, Validation Accuracy: 0.9166\n",
      "Epoch 3/25, Train Accuracy: 0.9237, Validation Accuracy: 0.9196\n",
      "Epoch 4/25, Train Accuracy: 0.9315, Validation Accuracy: 0.9218\n",
      "Epoch 5/25, Train Accuracy: 0.9389, Validation Accuracy: 0.9261\n",
      "Epoch 6/25, Train Accuracy: 0.9438, Validation Accuracy: 0.9286\n",
      "Epoch 7/25, Train Accuracy: 0.9487, Validation Accuracy: 0.9290\n",
      "Epoch 8/25, Train Accuracy: 0.9539, Validation Accuracy: 0.9278\n",
      "Epoch 9/25, Train Accuracy: 0.9582, Validation Accuracy: 0.9283\n",
      "Epoch 10/25, Train Accuracy: 0.9626, Validation Accuracy: 0.9299\n",
      "Epoch 11/25, Train Accuracy: 0.9645, Validation Accuracy: 0.9297\n",
      "Epoch 12/25, Train Accuracy: 0.9679, Validation Accuracy: 0.9275\n",
      "Epoch 13/25, Train Accuracy: 0.9704, Validation Accuracy: 0.9225\n",
      "Epoch 14/25, Train Accuracy: 0.9720, Validation Accuracy: 0.9295\n",
      "Epoch 15/25, Train Accuracy: 0.9748, Validation Accuracy: 0.9299\n",
      "Epoch 16/25, Train Accuracy: 0.9756, Validation Accuracy: 0.9313\n",
      "Epoch 17/25, Train Accuracy: 0.9767, Validation Accuracy: 0.9323\n",
      "Epoch 18/25, Train Accuracy: 0.9788, Validation Accuracy: 0.9311\n",
      "Epoch 19/25, Train Accuracy: 0.9798, Validation Accuracy: 0.9285\n",
      "Epoch 20/25, Train Accuracy: 0.9811, Validation Accuracy: 0.9310\n",
      "Epoch 21/25, Train Accuracy: 0.9819, Validation Accuracy: 0.9284\n",
      "Epoch 22/25, Train Accuracy: 0.9832, Validation Accuracy: 0.9307\n",
      "Epoch 23/25, Train Accuracy: 0.9838, Validation Accuracy: 0.9332\n",
      "Epoch 24/25, Train Accuracy: 0.9861, Validation Accuracy: 0.9292\n",
      "Epoch 25/25, Train Accuracy: 0.9842, Validation Accuracy: 0.9274\n",
      "\n",
      "Training time:  319.71498441696167\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Addition of Batch Normalization layers after Conv2D and before ReLU in the new model.\",\n",
      "        \"Introduction of a 'resblock' structure in the new model which likely includes skipped connections.\",\n",
      "        \"Addition of a Dropout layer with a dropout rate of 0.5 before the final fully connected layer in the new model.\",\n",
      "        \"Additional Batch Normalization layer in the new model before the last ReLU activation.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"The improvements in performance can be attributed to the addition of Batch Normalization layers which help in reducing internal covariate shift, thereby making the network faster and more stable. The residual blocks can prevent the degradation problem and improve learning, and the Dropout layer helps in reducing overfitting by providing regularization.\",\n",
      "    \"model_overfit\": true,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Implement early stopping to halt training when validation performance degrades, preventing further overfitting.\",\n",
      "        \"Experiment with different dropout rates or add dropout in other layers to improve generalization.\",\n",
      "        \"Adjust the layers within 'resblock' or consider adding more residual blocks if that fits within computational constraints to enhance the model's ability to learn complex patterns.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"Adam\",\n",
      "    \"how_many_epochs_to_choose\": 17,\n",
      "    \"learning_rate_choice\": 0.0001,\n",
      "    \"summary\": \"The new model employs Batch Normalization, residual connections, and Dropout which contribute to its enhanced performance over the old model by stabilizing training, encouraging healthier gradients, and mitigating overfitting. However, the model shows signs of overfitting post roughly 17 epochs as validation accuracy plateaus and begins to decrease. Thus, early stopping around 17 epochs, adjusting dropout implementations, and playing around with learning rate adjustments are recommended.\"\n",
      "}\n",
      "Iteration cost:  20.819519999999997\n",
      "Iteration:  2\n",
      "{\n",
      "  \"layer_0\": {\n",
      "    \"type\": \"Conv2d\",\n",
      "    \"in_channels\": \"1\",\n",
      "    \"out_channels\": \"32\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_1\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"32\"\n",
      "  },\n",
      "  \"layer_2\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_3\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_4\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"32\",\n",
      "    \"out_channels\": \"64\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_5\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"64\"\n",
      "  },\n",
      "  \"layer_6\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_7\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_8\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.3\"\n",
      "  },\n",
      "  \"layer_9\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"64\",\n",
      "    \"out_channels\": \"128\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_10\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_11\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_12\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_13\": {\n",
      "    \"type\": \"Flatten\",\n",
      "    \"start_dim\": \"1\",\n",
      "    \"end_dim\": \"-1\"\n",
      "  },\n",
      "  \"layer_14\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"1152\",\n",
      "    \"out_features\": \"128\",\n",
      "    \"bias\": \"true\"\n",
      "  },\n",
      "  \"layer_15\": {\n",
      "    \"type\": \"BatchNorm1d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_16\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_17\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.4\"\n",
      "  },\n",
      "  \"layer_18\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"128\",\n",
      "    \"out_features\": \"10\",\n",
      "    \"bias\": \"true\"\n",
      "  }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU()\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (14): Linear(in_features=1152, out_features=128, bias=True)\n",
      "  (15): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Dropout(p=0.4, inplace=False)\n",
      "  (18): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  0.51969 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [06:13<00:00, 14.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8611, Validation Accuracy: 0.9002\n",
      "Epoch 2/25, Train Accuracy: 0.9029, Validation Accuracy: 0.9102\n",
      "Epoch 3/25, Train Accuracy: 0.9132, Validation Accuracy: 0.9112\n",
      "Epoch 4/25, Train Accuracy: 0.9219, Validation Accuracy: 0.9236\n",
      "Epoch 5/25, Train Accuracy: 0.9284, Validation Accuracy: 0.9228\n",
      "Epoch 6/25, Train Accuracy: 0.9331, Validation Accuracy: 0.9281\n",
      "Epoch 7/25, Train Accuracy: 0.9384, Validation Accuracy: 0.9267\n",
      "Epoch 8/25, Train Accuracy: 0.9409, Validation Accuracy: 0.9311\n",
      "Epoch 9/25, Train Accuracy: 0.9449, Validation Accuracy: 0.9315\n",
      "Epoch 10/25, Train Accuracy: 0.9489, Validation Accuracy: 0.9303\n",
      "Epoch 11/25, Train Accuracy: 0.9517, Validation Accuracy: 0.9349\n",
      "Epoch 12/25, Train Accuracy: 0.9544, Validation Accuracy: 0.9334\n",
      "Epoch 13/25, Train Accuracy: 0.9568, Validation Accuracy: 0.9318\n",
      "Epoch 14/25, Train Accuracy: 0.9596, Validation Accuracy: 0.9317\n",
      "Epoch 15/25, Train Accuracy: 0.9618, Validation Accuracy: 0.9305\n",
      "Epoch 16/25, Train Accuracy: 0.9642, Validation Accuracy: 0.9358\n",
      "Epoch 17/25, Train Accuracy: 0.9655, Validation Accuracy: 0.9328\n",
      "Epoch 18/25, Train Accuracy: 0.9673, Validation Accuracy: 0.9334\n",
      "Epoch 19/25, Train Accuracy: 0.9695, Validation Accuracy: 0.9326\n",
      "Epoch 20/25, Train Accuracy: 0.9710, Validation Accuracy: 0.9361\n",
      "Epoch 21/25, Train Accuracy: 0.9708, Validation Accuracy: 0.9386\n",
      "Epoch 22/25, Train Accuracy: 0.9726, Validation Accuracy: 0.9356\n",
      "Epoch 23/25, Train Accuracy: 0.9753, Validation Accuracy: 0.9371\n",
      "Epoch 24/25, Train Accuracy: 0.9741, Validation Accuracy: 0.9360\n",
      "Epoch 25/25, Train Accuracy: 0.9751, Validation Accuracy: 0.9378\n",
      "\n",
      "Training time:  373.2067904472351\n",
      "\n",
      "\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Current model has an additional resblock between the first Dropout layer and BatchNorm2d.\",\n",
      "        \"Current model has higher Dropout rate (0.4 vs 0.5) in the second Dropout layer.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"The additional resblock likely helped in learning more complex features from the images, and higher dropout reduced overfitting.\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Include more data augmentation techniques to increase the robustness of the model.\",\n",
      "        \"Experiment with different kernel sizes in convolutional layers to see if smaller or larger kernels capture better features.\",\n",
      "        \"Try using other forms of normalization like Instance or Group normalization for different effects on model training dynamics.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"Adam\",\n",
      "    \"how_many_epochs_to_choose\": 30,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The new model includes additional layers that aid in better generalization evidenced by higher validation accuracy. Adjustments such as added resblocks and increased dropout rates seem to help the model perform better. Further improvements can possibly be achieved by exploring different data augmentations, kernel sizes, and normalization techniques.\"\n",
      "}\n",
      "```\n",
      "Iteration cost:  21.96576\n",
      "Iteration:  3\n",
      "\n",
      "{\n",
      "  \"layer_0\": {\n",
      "    \"type\": \"Conv2d\",\n",
      "    \"in_channels\": \"1\",\n",
      "    \"out_channels\": \"32\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_1\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"32\"\n",
      "  },\n",
      "  \"layer_2\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_3\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_4\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"32\",\n",
      "    \"out_channels\": \"64\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_5\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"64\"\n",
      "  },\n",
      "  \"layer_6\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_7\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_8\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.3\"\n",
      "  },\n",
      "  \"layer_9\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"64\",\n",
      "    \"out_channels\": \"128\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_10\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_11\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_12\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_13\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"128\",\n",
      "    \"out_channels\": \"256\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_14\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"256\"\n",
      "  },\n",
      "  \"layer_15\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_16\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_17\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.4\"\n",
      "  },\n",
      "  \"layer_18\": {\n",
      "    \"type\": \"Flatten\",\n",
      "    \"start_dim\": \"1\",\n",
      "    \"end_dim\": \"-1\"\n",
      "  },\n",
      "  \"layer_19\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"1024\",\n",
      "    \"out_features\": \"128\",\n",
      "    \"bias\": \"true\"\n",
      "  },\n",
      "  \"layer_20\": {\n",
      "    \"type\": \"BatchNorm1d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_21\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_22\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.5\"\n",
      "  },\n",
      "  \"layer_23\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"128\",\n",
      "    \"out_features\": \"10\",\n",
      "    \"bias\": \"true\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU()\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): ReLU()\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Dropout(p=0.4, inplace=False)\n",
      "  (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  (19): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ReLU()\n",
      "  (22): Dropout(p=0.5, inplace=False)\n",
      "  (23): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.685002 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1 and mat2 shapes cannot be multiplied (64x256 and 1024x128)\n",
      "Failed to build and train model, attempting to correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration cost:  9.39456\n",
      "Iteration:  4\n",
      "{\n",
      "  \"layer_0\": {\n",
      "    \"type\": \"Conv2d\",\n",
      "    \"in_channels\": \"1\",\n",
      "    \"out_channels\": \"32\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_1\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"32\"\n",
      "  },\n",
      "  \"layer_2\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_3\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_4\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"32\",\n",
      "    \"out_channels\": \"64\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_5\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"64\"\n",
      "  },\n",
      "  \"layer_6\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_7\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_8\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.3\"\n",
      "  },\n",
      "  \"layer_9\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"64\",\n",
      "    \"out_channels\": \"128\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_10\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_11\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_12\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_13\": {\n",
      "    \"type\": \"resblock\",\n",
      "    \"in_channels\": \"128\",\n",
      "    \"out_channels\": \"256\",\n",
      "    \"kernel_size\": \"3\",\n",
      "    \"stride\": \"1\",\n",
      "    \"padding\": \"1\"\n",
      "  },\n",
      "  \"layer_14\": {\n",
      "    \"type\": \"BatchNorm2d\",\n",
      "    \"num_features\": \"256\"\n",
      "  },\n",
      "  \"layer_15\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_16\": {\n",
      "    \"type\": \"MaxPool2d\",\n",
      "    \"kernel_size\": \"2\",\n",
      "    \"stride\": \"2\",\n",
      "    \"padding\": \"0\"\n",
      "  },\n",
      "  \"layer_17\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.4\"\n",
      "  },\n",
      "  \"layer_18\": {\n",
      "    \"type\": \"Flatten\",\n",
      "    \"start_dim\": \"1\",\n",
      "    \"end_dim\": \"-1\"\n",
      "  },\n",
      "  \"layer_19\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"256\",\n",
      "    \"out_features\": \"128\",\n",
      "    \"bias\": \"true\"\n",
      "  },\n",
      "  \"layer_20\": {\n",
      "    \"type\": \"BatchNorm1d\",\n",
      "    \"num_features\": \"128\"\n",
      "  },\n",
      "  \"layer_21\": {\n",
      "    \"type\": \"ReLU\"\n",
      "  },\n",
      "  \"layer_22\": {\n",
      "    \"type\": \"Dropout\",\n",
      "    \"p\": \"0.5\"\n",
      "  },\n",
      "  \"layer_23\": {\n",
      "    \"type\": \"Linear\",\n",
      "    \"in_features\": \"128\",\n",
      "    \"out_features\": \"10\",\n",
      "    \"bias\": \"true\"\n",
      "  }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU()\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): ReLU()\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Dropout(p=0.4, inplace=False)\n",
      "  (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  (19): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ReLU()\n",
      "  (22): Dropout(p=0.5, inplace=False)\n",
      "  (23): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [07:51<00:00, 18.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8410, Validation Accuracy: 0.8970\n",
      "Epoch 2/25, Train Accuracy: 0.8974, Validation Accuracy: 0.9060\n",
      "Epoch 3/25, Train Accuracy: 0.9090, Validation Accuracy: 0.9076\n",
      "Epoch 4/25, Train Accuracy: 0.9192, Validation Accuracy: 0.9169\n",
      "Epoch 5/25, Train Accuracy: 0.9259, Validation Accuracy: 0.9184\n",
      "Epoch 6/25, Train Accuracy: 0.9305, Validation Accuracy: 0.9241\n",
      "Epoch 7/25, Train Accuracy: 0.9342, Validation Accuracy: 0.9275\n",
      "Epoch 8/25, Train Accuracy: 0.9394, Validation Accuracy: 0.9293\n",
      "Epoch 9/25, Train Accuracy: 0.9440, Validation Accuracy: 0.9269\n",
      "Epoch 10/25, Train Accuracy: 0.9471, Validation Accuracy: 0.9336\n",
      "Epoch 11/25, Train Accuracy: 0.9498, Validation Accuracy: 0.9252\n",
      "Epoch 12/25, Train Accuracy: 0.9530, Validation Accuracy: 0.9325\n",
      "Epoch 13/25, Train Accuracy: 0.9558, Validation Accuracy: 0.9334\n",
      "Epoch 14/25, Train Accuracy: 0.9598, Validation Accuracy: 0.9350\n",
      "Epoch 15/25, Train Accuracy: 0.9616, Validation Accuracy: 0.9291\n",
      "Epoch 16/25, Train Accuracy: 0.9638, Validation Accuracy: 0.9278\n",
      "Epoch 17/25, Train Accuracy: 0.9677, Validation Accuracy: 0.9357\n",
      "Epoch 18/25, Train Accuracy: 0.9688, Validation Accuracy: 0.9327\n",
      "Epoch 19/25, Train Accuracy: 0.9701, Validation Accuracy: 0.9330\n",
      "Epoch 20/25, Train Accuracy: 0.9726, Validation Accuracy: 0.9381\n",
      "Epoch 21/25, Train Accuracy: 0.9743, Validation Accuracy: 0.9371\n",
      "Epoch 22/25, Train Accuracy: 0.9754, Validation Accuracy: 0.9332\n",
      "Epoch 23/25, Train Accuracy: 0.9772, Validation Accuracy: 0.9347\n",
      "Epoch 24/25, Train Accuracy: 0.9773, Validation Accuracy: 0.9320\n",
      "Epoch 25/25, Train Accuracy: 0.9787, Validation Accuracy: 0.9346\n",
      "\n",
      "Training time:  471.07004141807556\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"The current model has an additional resblock and batch normalization layer for 256 features, and more dropout regularization at higher probabilities.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"The addition of more deeper layers and increased dropout has likely helped improve the model's ability to generalize better on unseen data.\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Introduce data augmentation to further improve model robustness.\",\n",
      "        \"Experiment with different activation functions like LeakyReLU or ELU to see if they provide improvement over ReLU.\",\n",
      "        \"Increase data by adding more diverse dataset from different sources.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"RMSprop\",\n",
      "    \"how_many_epochs_to_choose\": 30,\n",
      "    \"learning_rate_choice\": 0.0005,\n",
      "    \"summary\": \"The newer model outperforms the older model marginally by incorporating an additional layer and increasing dropout, which helps in regularization. To further boost performance, experimenting with other forms of regularization and optimization techniques could be beneficial.\"\n",
      "}\n",
      "Iteration cost:  23.13504\n",
      "Iteration:  5\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"ReLU\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.3\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ELU(alpha=1.0)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ELU(alpha=1.0)\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): ELU(alpha=1.0)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Dropout(p=0.4, inplace=False)\n",
      "  (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  (19): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ELU(alpha=1.0)\n",
      "  (22): Dropout(p=0.5, inplace=False)\n",
      "  (23): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [08:04<00:00, 19.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8484, Validation Accuracy: 0.8954\n",
      "Epoch 2/25, Train Accuracy: 0.8992, Validation Accuracy: 0.9097\n",
      "Epoch 3/25, Train Accuracy: 0.9137, Validation Accuracy: 0.9095\n",
      "Epoch 4/25, Train Accuracy: 0.9228, Validation Accuracy: 0.9130\n",
      "Epoch 5/25, Train Accuracy: 0.9292, Validation Accuracy: 0.9237\n",
      "Epoch 6/25, Train Accuracy: 0.9344, Validation Accuracy: 0.9300\n",
      "Epoch 7/25, Train Accuracy: 0.9397, Validation Accuracy: 0.9192\n",
      "Epoch 8/25, Train Accuracy: 0.9446, Validation Accuracy: 0.9299\n",
      "Epoch 9/25, Train Accuracy: 0.9492, Validation Accuracy: 0.9320\n",
      "Epoch 10/25, Train Accuracy: 0.9536, Validation Accuracy: 0.9313\n",
      "Epoch 11/25, Train Accuracy: 0.9569, Validation Accuracy: 0.9309\n",
      "Epoch 12/25, Train Accuracy: 0.9619, Validation Accuracy: 0.9352\n",
      "Epoch 13/25, Train Accuracy: 0.9642, Validation Accuracy: 0.9314\n",
      "Epoch 14/25, Train Accuracy: 0.9680, Validation Accuracy: 0.9350\n",
      "Epoch 15/25, Train Accuracy: 0.9711, Validation Accuracy: 0.9315\n",
      "Epoch 16/25, Train Accuracy: 0.9737, Validation Accuracy: 0.9310\n",
      "Epoch 17/25, Train Accuracy: 0.9753, Validation Accuracy: 0.9324\n",
      "Epoch 18/25, Train Accuracy: 0.9771, Validation Accuracy: 0.9325\n",
      "Epoch 19/25, Train Accuracy: 0.9787, Validation Accuracy: 0.9342\n",
      "Epoch 20/25, Train Accuracy: 0.9811, Validation Accuracy: 0.9323\n",
      "Epoch 21/25, Train Accuracy: 0.9818, Validation Accuracy: 0.9321\n",
      "Epoch 22/25, Train Accuracy: 0.9832, Validation Accuracy: 0.9356\n",
      "Epoch 23/25, Train Accuracy: 0.9839, Validation Accuracy: 0.9364\n",
      "Epoch 24/25, Train Accuracy: 0.9848, Validation Accuracy: 0.9330\n",
      "Epoch 25/25, Train Accuracy: 0.9857, Validation Accuracy: 0.9336\n",
      "\n",
      "Training time:  484.2877278327942\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Activation function changed from ReLU to ELU in all layers\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"ELU activation function provided better handling of negative signals which could aid in learning more complex patterns\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Introduce additional data augmentation strategies to enhance generalization\",\n",
      "        \"Experiment with alternative regularization techniques\",\n",
      "        \"Tweak Dropout rates in different layers for better regularization\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"AdamW\",\n",
      "    \"how_many_epochs_to_choose\": 30,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The new model with ELU outperforms the older ReLU model slightly, suggesting better handling of information across the network. Overfitting doesn’t appear to be an issue. Improvements might still be seen with further tuning and complexity adjustments.\"\n",
      "}\n",
      "Iteration cost:  23.59872\n",
      "Iteration:  6\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.2\" \n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.35\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"ELU\",\n",
      "        \"alpha\": \"1.0\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ELU(alpha=1.0)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ELU(alpha=1.0)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.2, inplace=False)\n",
      "  (9): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ELU(alpha=1.0)\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): ELU(alpha=1.0)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Dropout(p=0.35, inplace=False)\n",
      "  (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  (19): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ELU(alpha=1.0)\n",
      "  (22): Dropout(p=0.5, inplace=False)\n",
      "  (23): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [07:56<00:00, 19.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8572, Validation Accuracy: 0.8845\n",
      "Epoch 2/25, Train Accuracy: 0.9036, Validation Accuracy: 0.9135\n",
      "Epoch 3/25, Train Accuracy: 0.9163, Validation Accuracy: 0.9141\n",
      "Epoch 4/25, Train Accuracy: 0.9260, Validation Accuracy: 0.9084\n",
      "Epoch 5/25, Train Accuracy: 0.9326, Validation Accuracy: 0.9246\n",
      "Epoch 6/25, Train Accuracy: 0.9393, Validation Accuracy: 0.9205\n",
      "Epoch 7/25, Train Accuracy: 0.9463, Validation Accuracy: 0.9207\n",
      "Epoch 8/25, Train Accuracy: 0.9513, Validation Accuracy: 0.9293\n",
      "Epoch 9/25, Train Accuracy: 0.9557, Validation Accuracy: 0.9278\n",
      "Epoch 10/25, Train Accuracy: 0.9607, Validation Accuracy: 0.9313\n",
      "Epoch 11/25, Train Accuracy: 0.9644, Validation Accuracy: 0.9274\n",
      "Epoch 12/25, Train Accuracy: 0.9689, Validation Accuracy: 0.9313\n",
      "Epoch 13/25, Train Accuracy: 0.9709, Validation Accuracy: 0.9263\n",
      "Epoch 14/25, Train Accuracy: 0.9748, Validation Accuracy: 0.9295\n",
      "Epoch 15/25, Train Accuracy: 0.9769, Validation Accuracy: 0.9285\n",
      "Epoch 16/25, Train Accuracy: 0.9794, Validation Accuracy: 0.9305\n",
      "Epoch 17/25, Train Accuracy: 0.9803, Validation Accuracy: 0.9282\n",
      "Epoch 18/25, Train Accuracy: 0.9828, Validation Accuracy: 0.9273\n",
      "Epoch 19/25, Train Accuracy: 0.9839, Validation Accuracy: 0.9258\n",
      "Epoch 20/25, Train Accuracy: 0.9849, Validation Accuracy: 0.9305\n",
      "Epoch 21/25, Train Accuracy: 0.9866, Validation Accuracy: 0.9288\n",
      "Epoch 22/25, Train Accuracy: 0.9879, Validation Accuracy: 0.9310\n",
      "Epoch 23/25, Train Accuracy: 0.9872, Validation Accuracy: 0.9292\n",
      "Epoch 24/25, Train Accuracy: 0.9889, Validation Accuracy: 0.9274\n",
      "Epoch 25/25, Train Accuracy: 0.9885, Validation Accuracy: 0.9292\n",
      "\n",
      "Training time:  476.5430746078491\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"The current model replaces the ReLU activation function with ELU in all instances, potentially impacting non-linearity handling and convergence behavior.\",\n",
      "        \"Dropout rates have been adjusted in the current model, which could affect regularization and overfitting. Specifically, there is a decrease in dropout probability from 0.3 to 0.2 in earlier layers and an adjustment from 0.4 to 0.35 in deeper layers.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": false,\n",
      "    \"why_performance_improved\": \"Although initialization showed promise, the current model did not maintain consistent superiority over the validation metrics from the previous model, suggesting inadequate architecture changes or insufficient tuning.\",\n",
      "    \"model_overfit\": true,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Introducing additional regularization techniques such as L2 regularization or data augmentation to combat overfitting.\",\n",
      "        \"Experimenting with different activation functions such as LeakyReLU to possibly improve training stability and performance.\",\n",
      "        \"Considering alternative or additional pooling layers (like average pooling) to test effects on feature extraction.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"SGD\",\n",
      "    \"how_many_epochs_to_choose\": 30,\n",
      "    \"learning_rate_choice\": 0.01,\n",
      "    \"summary\": \"The updated model incorporated changes in activation functions and dropout layers but did not conclusively outperform the previous version, indicating potential issues with either the modifications not going far enough or the need for more nuanced parameter tuning. Suggestions for further experiments include tweaking regularization, trying different optimizers like SGD, adjusting learning rates, potentially extending the training duration, and including diverse pooling methods.\"\n",
      "}\n",
      "Iteration cost:  25.43328\n",
      "Iteration:  7\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.3\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.01)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): LeakyReLU(negative_slope=0.01)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Dropout(p=0.3, inplace=False)\n",
      "  (9): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): LeakyReLU(negative_slope=0.01)\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): LeakyReLU(negative_slope=0.01)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Dropout(p=0.4, inplace=False)\n",
      "  (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  (19): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (20): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): LeakyReLU(negative_slope=0.01)\n",
      "  (22): Dropout(p=0.5, inplace=False)\n",
      "  (23): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [07:32<00:00, 18.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8422, Validation Accuracy: 0.9004\n",
      "Epoch 2/25, Train Accuracy: 0.8968, Validation Accuracy: 0.9137\n",
      "Epoch 3/25, Train Accuracy: 0.9094, Validation Accuracy: 0.9070\n",
      "Epoch 4/25, Train Accuracy: 0.9181, Validation Accuracy: 0.9181\n",
      "Epoch 5/25, Train Accuracy: 0.9257, Validation Accuracy: 0.9207\n",
      "Epoch 6/25, Train Accuracy: 0.9294, Validation Accuracy: 0.9249\n",
      "Epoch 7/25, Train Accuracy: 0.9356, Validation Accuracy: 0.9283\n",
      "Epoch 8/25, Train Accuracy: 0.9391, Validation Accuracy: 0.9297\n",
      "Epoch 9/25, Train Accuracy: 0.9434, Validation Accuracy: 0.9327\n",
      "Epoch 10/25, Train Accuracy: 0.9473, Validation Accuracy: 0.9258\n",
      "Epoch 11/25, Train Accuracy: 0.9499, Validation Accuracy: 0.9298\n",
      "Epoch 12/25, Train Accuracy: 0.9552, Validation Accuracy: 0.9357\n",
      "Epoch 13/25, Train Accuracy: 0.9567, Validation Accuracy: 0.9350\n",
      "Epoch 14/25, Train Accuracy: 0.9580, Validation Accuracy: 0.9343\n",
      "Epoch 15/25, Train Accuracy: 0.9617, Validation Accuracy: 0.9301\n",
      "Epoch 16/25, Train Accuracy: 0.9638, Validation Accuracy: 0.9316\n",
      "Epoch 17/25, Train Accuracy: 0.9661, Validation Accuracy: 0.9362\n",
      "Epoch 18/25, Train Accuracy: 0.9676, Validation Accuracy: 0.9338\n",
      "Epoch 19/25, Train Accuracy: 0.9690, Validation Accuracy: 0.9332\n",
      "Epoch 20/25, Train Accuracy: 0.9723, Validation Accuracy: 0.9338\n",
      "Epoch 21/25, Train Accuracy: 0.9735, Validation Accuracy: 0.9336\n",
      "Epoch 22/25, Train Accuracy: 0.9743, Validation Accuracy: 0.9347\n",
      "Epoch 23/25, Train Accuracy: 0.9756, Validation Accuracy: 0.9350\n",
      "Epoch 24/25, Train Accuracy: 0.9770, Validation Accuracy: 0.9369\n",
      "Epoch 25/25, Train Accuracy: 0.9783, Validation Accuracy: 0.9343\n",
      "\n",
      "Training time:  452.02895069122314\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Activation function changed from ELU to LeakyReLU with a negative slope of 0.01.\",\n",
      "        \"Dropout probability was adjusted in the final layers; it changed from 0.35 to 0.4 in the penultimate dropout layer and remained 0.5 in the last dropout layer.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"The new model, despite a lower start, achieves higher validation accuracy by the end due to the more robust generalization capabilities of LeakyReLU which helps prevent neurons from dying out, as opposed to ELU.\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Experiment with a slight increase in dropout rates in early layers to further enhance regularization.\",\n",
      "        \"Consider data augmentation techniques such as rotations or scaling to improve generalization.\",\n",
      "        \"Introduce learning rate scheduling or early stopping to fine-tune training process.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"adam\",\n",
      "    \"how_many_epochs_to_choose\": 25,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The new model shows better generalization possibly due to the utilization of LeakyReLU activation functions and a slightly higher dropout rate in the deeper layers, which helps in controlling overfitting. Maintaining a moderate learning rate helps in achieving a balance between convergence speed and training stability.\"\n",
      "}\n",
      "Iteration cost:  25.47072\n",
      "Iteration:  8\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.35\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.35\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_24\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_25\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.01)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Dropout(p=0.35, inplace=False)\n",
      "  (5): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): LeakyReLU(negative_slope=0.01)\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Dropout(p=0.35, inplace=False)\n",
      "  (10): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): LeakyReLU(negative_slope=0.01)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Dropout(p=0.4, inplace=False)\n",
      "  (15): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): LeakyReLU(negative_slope=0.01)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Dropout(p=0.5, inplace=False)\n",
      "  (20): Flatten(start_dim=1, end_dim=-1)\n",
      "  (21): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (22): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): LeakyReLU(negative_slope=0.01)\n",
      "  (24): Dropout(p=0.5, inplace=False)\n",
      "  (25): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [08:13<00:00, 19.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.7939, Validation Accuracy: 0.8847\n",
      "Epoch 2/25, Train Accuracy: 0.8708, Validation Accuracy: 0.8915\n",
      "Epoch 3/25, Train Accuracy: 0.8841, Validation Accuracy: 0.9020\n",
      "Epoch 4/25, Train Accuracy: 0.8922, Validation Accuracy: 0.9080\n",
      "Epoch 5/25, Train Accuracy: 0.8983, Validation Accuracy: 0.9160\n",
      "Epoch 6/25, Train Accuracy: 0.9027, Validation Accuracy: 0.9172\n",
      "Epoch 7/25, Train Accuracy: 0.9079, Validation Accuracy: 0.9188\n",
      "Epoch 8/25, Train Accuracy: 0.9106, Validation Accuracy: 0.9217\n",
      "Epoch 9/25, Train Accuracy: 0.9139, Validation Accuracy: 0.9199\n",
      "Epoch 10/25, Train Accuracy: 0.9178, Validation Accuracy: 0.9232\n",
      "Epoch 11/25, Train Accuracy: 0.9183, Validation Accuracy: 0.9299\n",
      "Epoch 12/25, Train Accuracy: 0.9222, Validation Accuracy: 0.9233\n",
      "Epoch 13/25, Train Accuracy: 0.9242, Validation Accuracy: 0.9299\n",
      "Epoch 14/25, Train Accuracy: 0.9258, Validation Accuracy: 0.9286\n",
      "Epoch 15/25, Train Accuracy: 0.9266, Validation Accuracy: 0.9319\n",
      "Epoch 16/25, Train Accuracy: 0.9294, Validation Accuracy: 0.9300\n",
      "Epoch 17/25, Train Accuracy: 0.9319, Validation Accuracy: 0.9337\n",
      "Epoch 18/25, Train Accuracy: 0.9318, Validation Accuracy: 0.9301\n",
      "Epoch 19/25, Train Accuracy: 0.9326, Validation Accuracy: 0.9349\n",
      "Epoch 20/25, Train Accuracy: 0.9352, Validation Accuracy: 0.9323\n",
      "Epoch 21/25, Train Accuracy: 0.9364, Validation Accuracy: 0.9374\n",
      "Epoch 22/25, Train Accuracy: 0.9371, Validation Accuracy: 0.9347\n",
      "Epoch 23/25, Train Accuracy: 0.9399, Validation Accuracy: 0.9364\n",
      "Epoch 24/25, Train Accuracy: 0.9381, Validation Accuracy: 0.9365\n",
      "Epoch 25/25, Train Accuracy: 0.9402, Validation Accuracy: 0.9343\n",
      "\n",
      "Training time:  493.4314045906067\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"The current model has an additional dropout layer 'layer_4' with dropout probability of 0.35 after the first max pooling layer which was not present in the old model.\",\n",
      "        \"In the old model, the dropout layers used different probabilities (0.3, 0.4 and 0.5) across layers while the current model uses a consistent dropout value of 0.35 for all except the final dropout layer which remains at 0.5.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"The improvement in the performance in the new model can be attributed to increased regulation through consistent use of dropout which might have helped in reducing overfitting thus making the model generalize better on unseen data.\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Integrate additional data augmentation methodologies during training to further improve model generalization.\",\n",
      "        \"Experiment with different configurations of dropout rates in the different layers or adaptively adjust dropout based on layer complexity.\",\n",
      "        \"Consider exploring deeper architectures or slightly increasing the kernel sizes to capture more complex patterns if computational resources allow.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"Adam\",\n",
      "    \"how_many_epochs_to_choose\": 25,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The new model shows improved performance compared to the old model by employing consistent dropout rates, which helps in mitigating any overfitting to the training data, thus enhancing generalization to unseen data. Further enhancements can include deeper network architectures or advanced regularization techniques.\"\n",
      "}\n",
      "Iteration cost:  26.222399999999997\n",
      "Iteration:  9\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.3\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.3\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"LeakyReLU\",\n",
      "        \"negative_slope\": \"0.01\"\n",
      "    },\n",
      "    \"layer_24\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_25\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.01)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Dropout(p=0.3, inplace=False)\n",
      "  (5): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): LeakyReLU(negative_slope=0.01)\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Dropout(p=0.3, inplace=False)\n",
      "  (10): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): LeakyReLU(negative_slope=0.01)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Dropout(p=0.4, inplace=False)\n",
      "  (15): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): LeakyReLU(negative_slope=0.01)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Dropout(p=0.5, inplace=False)\n",
      "  (20): Flatten(start_dim=1, end_dim=-1)\n",
      "  (21): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (22): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): LeakyReLU(negative_slope=0.01)\n",
      "  (24): Dropout(p=0.5, inplace=False)\n",
      "  (25): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [07:41<00:00, 18.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.7966, Validation Accuracy: 0.8741\n",
      "Epoch 2/25, Train Accuracy: 0.8727, Validation Accuracy: 0.8976\n",
      "Epoch 3/25, Train Accuracy: 0.8875, Validation Accuracy: 0.9069\n",
      "Epoch 4/25, Train Accuracy: 0.8979, Validation Accuracy: 0.9117\n",
      "Epoch 5/25, Train Accuracy: 0.9013, Validation Accuracy: 0.9139\n",
      "Epoch 6/25, Train Accuracy: 0.9081, Validation Accuracy: 0.9182\n",
      "Epoch 7/25, Train Accuracy: 0.9114, Validation Accuracy: 0.9208\n",
      "Epoch 8/25, Train Accuracy: 0.9140, Validation Accuracy: 0.9218\n",
      "Epoch 9/25, Train Accuracy: 0.9170, Validation Accuracy: 0.9214\n",
      "Epoch 10/25, Train Accuracy: 0.9204, Validation Accuracy: 0.9228\n",
      "Epoch 11/25, Train Accuracy: 0.9241, Validation Accuracy: 0.9249\n",
      "Epoch 12/25, Train Accuracy: 0.9253, Validation Accuracy: 0.9304\n",
      "Epoch 13/25, Train Accuracy: 0.9275, Validation Accuracy: 0.9290\n",
      "Epoch 14/25, Train Accuracy: 0.9299, Validation Accuracy: 0.9270\n",
      "Epoch 15/25, Train Accuracy: 0.9314, Validation Accuracy: 0.9244\n",
      "Epoch 16/25, Train Accuracy: 0.9325, Validation Accuracy: 0.9310\n",
      "Epoch 17/25, Train Accuracy: 0.9341, Validation Accuracy: 0.9321\n",
      "Epoch 18/25, Train Accuracy: 0.9360, Validation Accuracy: 0.9311\n",
      "Epoch 19/25, Train Accuracy: 0.9375, Validation Accuracy: 0.9330\n",
      "Epoch 20/25, Train Accuracy: 0.9381, Validation Accuracy: 0.9359\n",
      "Epoch 21/25, Train Accuracy: 0.9393, Validation Accuracy: 0.9352\n",
      "Epoch 22/25, Train Accuracy: 0.9419, Validation Accuracy: 0.9363\n",
      "Epoch 23/25, Train Accuracy: 0.9433, Validation Accuracy: 0.9325\n",
      "Epoch 24/25, Train Accuracy: 0.9435, Validation Accuracy: 0.9349\n",
      "Epoch 25/25, Train Accuracy: 0.9442, Validation Accuracy: 0.9365\n",
      "\n",
      "Training time:  461.100932598114\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Dropout probability in early and middle layers (layer_4 and layer_9) was reduced from 0.35 to 0.3 in the new model.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"Reduced dropout probability likely helped the model retain more information during training and generalize better to the validation dataset.\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Experiment with different activation functions like Mish or Swish to potentially improve nonlinear learning capabilities.\",\n",
      "        \"Add data augmentation techniques such as random rotations, scaling, or color augmentation to increase dataset robustness and further improve generalization.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"Adam\",\n",
      "    \"how_many_epochs_to_choose\": 25,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The new model showed improvements due to optimized dropout rates, helping it learn better without losing essential data during training. Further improvements could be achieved by tuning activation functions, using advanced data augmentation, and maintaining the optimizer and training period settings.\"\n",
      "}\n",
      "Iteration cost:  24.74496\n",
      "Iteration:  10\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.25\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.25\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_24\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.5\"\n",
      "    },\n",
      "    \"layer_25\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Mish()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Dropout(p=0.25, inplace=False)\n",
      "  (5): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Mish()\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Dropout(p=0.25, inplace=False)\n",
      "  (10): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): Mish()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Dropout(p=0.4, inplace=False)\n",
      "  (15): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): Mish()\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Dropout(p=0.5, inplace=False)\n",
      "  (20): Flatten(start_dim=1, end_dim=-1)\n",
      "  (21): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (22): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): Mish()\n",
      "  (24): Dropout(p=0.5, inplace=False)\n",
      "  (25): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [08:13<00:00, 19.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8185, Validation Accuracy: 0.8872\n",
      "Epoch 2/25, Train Accuracy: 0.8826, Validation Accuracy: 0.8997\n",
      "Epoch 3/25, Train Accuracy: 0.8970, Validation Accuracy: 0.9021\n",
      "Epoch 4/25, Train Accuracy: 0.9045, Validation Accuracy: 0.9157\n",
      "Epoch 5/25, Train Accuracy: 0.9093, Validation Accuracy: 0.9166\n",
      "Epoch 6/25, Train Accuracy: 0.9153, Validation Accuracy: 0.9253\n",
      "Epoch 7/25, Train Accuracy: 0.9193, Validation Accuracy: 0.9256\n",
      "Epoch 8/25, Train Accuracy: 0.9225, Validation Accuracy: 0.9268\n",
      "Epoch 9/25, Train Accuracy: 0.9276, Validation Accuracy: 0.9250\n",
      "Epoch 10/25, Train Accuracy: 0.9294, Validation Accuracy: 0.9323\n",
      "Epoch 11/25, Train Accuracy: 0.9329, Validation Accuracy: 0.9254\n",
      "Epoch 12/25, Train Accuracy: 0.9348, Validation Accuracy: 0.9315\n",
      "Epoch 13/25, Train Accuracy: 0.9365, Validation Accuracy: 0.9313\n",
      "Epoch 14/25, Train Accuracy: 0.9400, Validation Accuracy: 0.9323\n",
      "Epoch 15/25, Train Accuracy: 0.9421, Validation Accuracy: 0.9310\n",
      "Epoch 16/25, Train Accuracy: 0.9439, Validation Accuracy: 0.9334\n",
      "Epoch 17/25, Train Accuracy: 0.9472, Validation Accuracy: 0.9328\n",
      "Epoch 18/25, Train Accuracy: 0.9480, Validation Accuracy: 0.9348\n",
      "Epoch 19/25, Train Accuracy: 0.9501, Validation Accuracy: 0.9359\n",
      "Epoch 20/25, Train Accuracy: 0.9497, Validation Accuracy: 0.9358\n",
      "Epoch 21/25, Train Accuracy: 0.9518, Validation Accuracy: 0.9376\n",
      "Epoch 22/25, Train Accuracy: 0.9534, Validation Accuracy: 0.9396\n",
      "Epoch 23/25, Train Accuracy: 0.9546, Validation Accuracy: 0.9379\n",
      "Epoch 24/25, Train Accuracy: 0.9579, Validation Accuracy: 0.9383\n",
      "Epoch 25/25, Train Accuracy: 0.9584, Validation Accuracy: 0.9361\n",
      "\n",
      "Training time:  493.2073292732239\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Activation function changed from LeakyReLU to Mish.\",\n",
      "        \"Dropout probabilities adjusted in some layers, decreasing in earlier stages.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"Mish activation function likely provided better handling of negative values, possibly enabling better gradient flow, and the slight adjustments in dropout rates could have helped in regularizing the model more effectively at different stages of the network.\",\n",
      "    \"model_overfit\": false,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Introduce early stopping to prevent unnecessary training and potential overfitting after performance plateaus.\",\n",
      "        \"Experiment with data augmentation techniques to increase dataset diversity and robustness of the model.\",\n",
      "        \"Adjust dropout rates further based on detailed layer-wise analysis of activation and gradient flow or considering adaptive dropout.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"Adam\",\n",
      "    \"how_many_epochs_to_choose\": 22,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The updated model using the Mish activation function and optimized dropout rates improved performance on the validation set. Further enhancements can be achieved by refining regularization techniques and stopping training early upon convergence to prevent the slight overfitting observed in the latter epochs.\"\n",
      "}\n",
      "Iteration cost:  24.77376\n",
      "Iteration:  11\n",
      "\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.2\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.2\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.3\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.3\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_24\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_25\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Mish()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Mish()\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Dropout(p=0.2, inplace=False)\n",
      "  (10): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): Mish()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Dropout(p=0.3, inplace=False)\n",
      "  (15): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): Mish()\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Dropout(p=0.3, inplace=False)\n",
      "  (20): Flatten(start_dim=1, end_dim=-1)\n",
      "  (21): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (22): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): Mish()\n",
      "  (24): Dropout(p=0.4, inplace=False)\n",
      "  (25): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [08:15<00:00, 19.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Accuracy: 0.8448, Validation Accuracy: 0.8867\n",
      "Epoch 2/25, Train Accuracy: 0.8936, Validation Accuracy: 0.8976\n",
      "Epoch 3/25, Train Accuracy: 0.9059, Validation Accuracy: 0.9106\n",
      "Epoch 4/25, Train Accuracy: 0.9133, Validation Accuracy: 0.9187\n",
      "Epoch 5/25, Train Accuracy: 0.9194, Validation Accuracy: 0.9243\n",
      "Epoch 6/25, Train Accuracy: 0.9253, Validation Accuracy: 0.9231\n",
      "Epoch 7/25, Train Accuracy: 0.9293, Validation Accuracy: 0.9262\n",
      "Epoch 8/25, Train Accuracy: 0.9342, Validation Accuracy: 0.9300\n",
      "Epoch 9/25, Train Accuracy: 0.9387, Validation Accuracy: 0.9328\n",
      "Epoch 10/25, Train Accuracy: 0.9409, Validation Accuracy: 0.9346\n",
      "Epoch 11/25, Train Accuracy: 0.9435, Validation Accuracy: 0.9323\n",
      "Epoch 12/25, Train Accuracy: 0.9462, Validation Accuracy: 0.9345\n",
      "Epoch 13/25, Train Accuracy: 0.9492, Validation Accuracy: 0.9333\n",
      "Epoch 14/25, Train Accuracy: 0.9518, Validation Accuracy: 0.9352\n",
      "Epoch 15/25, Train Accuracy: 0.9532, Validation Accuracy: 0.9378\n",
      "Epoch 16/25, Train Accuracy: 0.9561, Validation Accuracy: 0.9360\n",
      "Epoch 17/25, Train Accuracy: 0.9574, Validation Accuracy: 0.9391\n",
      "Epoch 18/25, Train Accuracy: 0.9598, Validation Accuracy: 0.9348\n",
      "Epoch 19/25, Train Accuracy: 0.9613, Validation Accuracy: 0.9386\n",
      "Epoch 20/25, Train Accuracy: 0.9631, Validation Accuracy: 0.9381\n",
      "Epoch 21/25, Train Accuracy: 0.9640, Validation Accuracy: 0.9390\n",
      "Epoch 22/25, Train Accuracy: 0.9664, Validation Accuracy: 0.9367\n",
      "Epoch 23/25, Train Accuracy: 0.9681, Validation Accuracy: 0.9368\n",
      "Epoch 24/25, Train Accuracy: 0.9676, Validation Accuracy: 0.9365\n",
      "Epoch 25/25, Train Accuracy: 0.9692, Validation Accuracy: 0.9335\n",
      "\n",
      "Training time:  495.6144120693207\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"differences_between_models\": [\n",
      "        \"Dropout probability was reduced in earlier layers and increased in the last linear layer in the new model.\"\n",
      "    ],\n",
      "    \"new_model_performance_better\": true,\n",
      "    \"why_performance_improved\": \"The adjustment in dropout rates likely helped the new model better generalize, reducing overfitting slightly while maintaining learning capacity in deeper layers.\",\n",
      "    \"model_overfit\": true,\n",
      "    \"how_to_improve_architecture_further\": [\n",
      "        \"Experiment with lower dropout rates in the early convolutional layers to see if performance can be improved further.\",\n",
      "        \"Introduce additional data augmentation techniques to further combat overfitting.\",\n",
      "        \"Consider using a learning rate scheduler to optimize learning rate during training.\"\n",
      "    ],\n",
      "    \"optimizer_choice\": \"AdamW\",\n",
      "    \"how_many_epochs_to_choose\": 30,\n",
      "    \"learning_rate_choice\": 0.001,\n",
      "    \"summary\": \"The new model shows improved performance likely due to better management of dropout rates which enhanced generalization. Further improvements might include adjusting the dropout configuration, advanced regularization strategies, and refining the learning rate over the training period.\"\n",
      "}\n",
      "Iteration cost:  24.20064\n",
      "Iteration:  12\n",
      "{\n",
      "    \"layer_0\": {\n",
      "        \"type\": \"Conv2d\",\n",
      "        \"in_channels\": \"1\",\n",
      "        \"out_channels\": \"32\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_1\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"32\"\n",
      "    },\n",
      "    \"layer_2\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_3\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_4\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.1\"\n",
      "    },\n",
      "    \"layer_5\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"32\",\n",
      "        \"out_channels\": \"64\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_6\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"64\"\n",
      "    },\n",
      "    \"layer_7\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_8\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_9\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.1\"\n",
      "    },\n",
      "    \"layer_10\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"64\",\n",
      "        \"out_channels\": \"128\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_11\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_12\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_13\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_14\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.2\"\n",
      "    },\n",
      "    \"layer_15\": {\n",
      "        \"type\": \"resblock\",\n",
      "        \"in_channels\": \"128\",\n",
      "        \"out_channels\": \"256\",\n",
      "        \"kernel_size\": \"3\",\n",
      "        \"stride\": \"1\",\n",
      "        \"padding\": \"1\"\n",
      "    },\n",
      "    \"layer_16\": {\n",
      "        \"type\": \"BatchNorm2d\",\n",
      "        \"num_features\": \"256\"\n",
      "    },\n",
      "    \"layer_17\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_18\": {\n",
      "        \"type\": \"MaxPool2d\",\n",
      "        \"kernel_size\": \"2\",\n",
      "        \"stride\": \"2\",\n",
      "        \"padding\": \"0\"\n",
      "    },\n",
      "    \"layer_19\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.2\"\n",
      "    },\n",
      "    \"layer_20\": {\n",
      "        \"type\": \"Flatten\",\n",
      "        \"start_dim\": \"1\",\n",
      "        \"end_dim\": \"-1\"\n",
      "    },\n",
      "    \"layer_21\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"256\",\n",
      "        \"out_features\": \"128\",\n",
      "        \"bias\": \"true\"\n",
      "    },\n",
      "    \"layer_22\": {\n",
      "        \"type\": \"BatchNorm1d\",\n",
      "        \"num_features\": \"128\"\n",
      "    },\n",
      "    \"layer_23\": {\n",
      "        \"type\": \"Mish\"\n",
      "    },\n",
      "    \"layer_24\": {\n",
      "        \"type\": \"Dropout\",\n",
      "        \"p\": \"0.4\"\n",
      "    },\n",
      "    \"layer_25\": {\n",
      "        \"type\": \"Linear\",\n",
      "        \"in_features\": \"128\",\n",
      "        \"out_features\": \"10\",\n",
      "        \"bias\": \"true\"\n",
      "    }\n",
      "}\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Mish()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "  (5): ResidualBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Mish()\n",
      "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Dropout(p=0.1, inplace=False)\n",
      "  (10): ResidualBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): Mish()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Dropout(p=0.2, inplace=False)\n",
      "  (15): ResidualBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): Mish()\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Dropout(p=0.2, inplace=False)\n",
      "  (20): Flatten(start_dim=1, end_dim=-1)\n",
      "  (21): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (22): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): Mish()\n",
      "  (24): Dropout(p=0.4, inplace=False)\n",
      "  (25): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters:  1.586698 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████▏             | 17/25 [05:30<02:37, 19.72s/it]"
     ]
    }
   ],
   "source": [
    "send_price = 2.88 / 1000\n",
    "receive_price = 8.64 / 1000\n",
    "context = ''\n",
    "num_epochs = 25\n",
    "i = 0\n",
    "discovered_error = None\n",
    "test_results = []\n",
    "train_results = []\n",
    "times = []\n",
    "fail_count = 0\n",
    "num_iters = 40\n",
    "models = []\n",
    "summaries = []\n",
    "gpu_ids = [3]\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"LLM-NAS-Experiments\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"epochs\": num_epochs,\n",
    "    \"iters\": num_iters,\n",
    "    \"model\": \"GPT-4\",\n",
    "    \"data_augmentation\": \"None\",\n",
    "    \"pipeline\": \"Basic\"\n",
    "    }\n",
    ")\n",
    "\n",
    "while i < num_iters:\n",
    "    cost_per_iter = 0\n",
    "    training_time = None\n",
    "    test_acc = None\n",
    "    train_acc = None\n",
    "    n_params = None\n",
    "    print('Iteration: ', i)\n",
    "    i += 1\n",
    "    # try building and training the model\n",
    "    try:\n",
    "        print(model_string)\n",
    "        model = build_model(json.loads(model_string))\n",
    "        print(model)\n",
    "        n_params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000\n",
    "        print('Number of parameters: ', n_params, 'M')\n",
    "        start = time.time()\n",
    "        summary, train_acc, test_acc = train_and_evaluate(model, train_loader, test_loader, num_epochs, gpu_ids=gpu_ids)\n",
    "        train_results.append(train_acc)\n",
    "        test_results.append(test_acc)  \n",
    "        end = time.time()\n",
    "        print(summary)\n",
    "        training_time = end-start\n",
    "        print(\"Training time: \", training_time)\n",
    "        times.append(training_time)\n",
    "        print('\\n\\n')\n",
    "        discovered_error = None\n",
    "        models.append(model_string)\n",
    "        summaries.append(summary)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Failed to build and train model, attempting to correct\")\n",
    "        fail_count += 1\n",
    "        discovered_error = e\n",
    "\n",
    "    # update model\n",
    "    try:\n",
    "        if discovered_error is None:\n",
    "            if len(models) == 1:\n",
    "                model_string, usage = get_new_model(data_description, task_description, model_string, summary)\n",
    "                prompt_tokens = usage.prompt_tokens\n",
    "                completion_tokens = usage.completion_tokens\n",
    "                cost = prompt_tokens * send_price + completion_tokens * receive_price\n",
    "                cost_per_iter += cost\n",
    "          \n",
    "            else:\n",
    "                reflection, usage = reflect(data_description, task_description, models[-2], models[-1], summaries[-2], summaries[-1], reflection_format)\n",
    "                print(reflection)\n",
    "                prompt_tokens = usage.prompt_tokens\n",
    "                completion_tokens = usage.completion_tokens\n",
    "                cost = prompt_tokens * send_price + completion_tokens * receive_price\n",
    "                cost_per_iter += cost\n",
    "                model_string, usage = get_new_model(data_description, task_description, model_string, summary, reflection)\n",
    "                prompt_tokens = usage.prompt_tokens\n",
    "                completion_tokens = usage.completion_tokens\n",
    "                cost = prompt_tokens * send_price + completion_tokens * receive_price\n",
    "                cost_per_iter += cost\n",
    "        else:\n",
    "            model_string, usage = fix_model(model_string, discovered_error)\n",
    "            prompt_tokens = usage.prompt_tokens\n",
    "            completion_tokens = usage.completion_tokens\n",
    "            cost = prompt_tokens * send_price + completion_tokens * receive_price\n",
    "            cost_per_iter += cost\n",
    "        print(\"Iteration cost: \", cost_per_iter)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        wandb.finish()\n",
    "        raise Exception('Failed to connect to API or parse the response')\n",
    "    if discovered_error == None:\n",
    "        wandb.log({\"test_acc\": test_acc, \"train_acc\": train_acc, \"time\": training_time, \"cost\": cost_per_iter, \"M_parameters\": n_params})\n",
    "    else:\n",
    "        wandb.log({\"test_acc\": 0, \"train_acc\": 0, \"time\": 0, \"cost\": cost_per_iter, \"M_parameters\": n_params})\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e44de3-6cfd-421b-a056-f1998fb17bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
